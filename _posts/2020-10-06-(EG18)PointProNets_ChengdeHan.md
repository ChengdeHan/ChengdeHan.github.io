---
layout: mypost
title: (EG18)PointProNets Consolidation of Point Clouds with Convolutional Neural Networks
categories: [PaperNote]
---

<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      inlineMath: [['$','$']]
    }
  });
</script>
# (EG18)PointProNets Consolidation of Point Clouds with Convolutional Neural Networks

## 1.Contributions

- The **first deep learning method** for **local point cloud processing** with a fully differentiable architecture that we call PointProNet. A key component in this architecture is **a differentiable points projection layer** for **converting unordered points to regularly sampled height maps**. Although we use the architecture for consolidation, it can also be used for revising further point cloud processing tasks.

- An **end-to-end** data-driven algorithm for consolidation of unorganized point clouds that leads to **very accurate surface representations**, with significant quantitative and visual improvements over the previous methods.

## 2.Network Architecture

The **main idea** of our techniqueis to **learn a local mapping** that **transform** seach set of **points** extracted from a local patch of the input point cloud **to** its **consolidated version**, where the output points sample the underlying surface very accurately and densely. The union of all such local output sets **give us** the final outputpoint cloud.

![Image]((EG18)PointProNets_ChengdeHan.assets/Image.png)

## 3.Training

### 3.1 输入的训练样本

是针对输入的点云数据的每一个点生成的patch进行训练的，**变相是一个逐点的网络**，这里的每个点都包含着**局部信息**。

For each model in the training sets, **ground truth point sets** **are twice as dense as the input point sets**, and are generated by Poisson disk sampling for equal distribution of points. Synthetic **Gaussian noise** was dynamically **added to the input points** at training time, as the training patches were generated.

#### 3.1.1对于每个点生成相应的patch

 **（an input patch  $\mathcal{X}$,  the corresponding ground truth output patch $\mathcal{Y}_{GT}$)**

- These are cut out from input and ground truth output point clouds in spherical neighborhoods of radius r.

- When feeding data to the network during training, pairs ($\mathcal{X}$, $\mathcal{Y}_{GT}$ ) are randomly extracted from the training point clouds by positioning centers of the neighborhoods at random points in input point clouds. We thus get a dense coverage of each geometry in the database. Finally, we further augment the patch pairs dataset by random resampling of the input point clouds, getting an arbitrary sampling rate for each $\mathcal{X}$. The number of points can then be matched to $\textbf{n}$ by random down-sampling or replication of points in $\mathcal{X}$, as the network expects a fixed-size input matrix $X$.

#### 3.1.2对于每个patch生成的Ground Truth Heightmap 

Ground Truth Heightmap 的产生需要真实的法向量 $\textbf{n}_{GT}$ 和与之正交的单位向量 $\textbf{d}_{GT}$

In practice, we set the vector  $\textbf{n}_{GT}$ as the average of the normals of the points in the consolidated set $\mathcal{Y}_{GT}$ . Due to the high density of $\mathcal{Y}_{GT}$ , its uniform sampling, and lack of noise, we found this average is robust for capturing local geometries for the patch sizes we consider.

We thus want to find a normalized vector $\textbf{n}_{GT}$ of a proper image plane positioned at an offset -$r*\textbf{n}_{GT}$(to avoid negative distances).

#### 3.1.3增加patch层次训练的数据量 

Note that the orientation of $\textbf{n}_{GT}$ is ambiguous: both $n_{GT}$ and $-n_{GT}$would produce a valid heightmap, even though the resulting images can be substantially different. We thus choose the sign of $n_{GT}$randomly for every patch, in order to ensure that we feed the network with varied data. The vector $\textbf{d}_{GT}$ defines rotation of heightmaps on the image plane. We choose a random $\textbf{d}_{GT}$ orthogonal to $\textbf{n}_{GT}$ to make the learned representation invariant to this degree of freedom.  (对于每个patch来言，$\textbf{n}_{GT}$和$-\textbf{n}_{GT}$来说没有什么影响，只要这个方向是对的，虽然是相反的，但是会让他强行对齐$\textbf{n}_{GT}$的方向。而对于$\textbf{d}_{GT}$的方向，只要是垂直于$\textbf{n}_{GT}$，投影得到的高度图不会有任何变化。所以这两个随机对高度图的产生没有影响，随机赋值的话，就可以更鲁棒)

### 3.2 Heightmap Generation Network

#### **3.2.1Frame Estimator**

In our method, we adopt the same architecture but modify the output of the final fully connected layers to produce the 3D vector n. Additionally, it would be beneficial that the learned representation is invariant to translations and rotations of X. We achieve this by centering the points in X by subtracting the patch center, and by feeding patches with random rotations at training time.

![image-20200820212617945]((EG18)PointProNets_ChengdeHan.assets/image-20200820212617945.png)

通过pointnet 的框架学到了法向量 $\textbf{n}$ 之后，将其对齐到 $\textbf{n}_{GT}$ 的方向。然后找到一个跟 $\textbf{d}_{GT}$ 最接近的一个 $\textbf{d}$.
$$
\textbf{n}=\textbf{n}(\textbf{n}^{T}\textbf{n}_{GT}),  \textbf{d}=\textbf{d}_{GT}-(\textbf{d}^{T}_{GT}\textbf{n})\textbf{n}
$$

#### **3.2.2Projector**

对于每一个点 $\textbf{x} \in \mathcal{X}$,  定义投影到法向量于与之对应的正交向量张成的平面上的点如下：
$$
\textbf{p}=\textbf{x}-(\textbf{x}^{T}\textbf{n}+r)\textbf{n}
$$
对于每一个点 $\textbf{p}$ ，计算到点 $\textbf{x}$ 的距离 $\| \textbf{x}-\textbf{p}\|$. 然后将点 $\textbf{p}$ 转到图像坐标系，
$$
\textbf{i}= \frac{k}{2r}[\textbf{p}^{T}\textbf{d}+r\frac{\textbf{n}\times \textbf{d}}{\| \textbf{n}\times \textbf{d}\|}+r]
$$
![image-20200820215525143]((EG18)PointProNets_ChengdeHan.assets/image-20200820215525143.png)

### 3.3Heightmap Denoising Network

![image-20200820215749478]((EG18)PointProNets_ChengdeHan.assets/image-20200820215749478.png)

![image-20200820215823727]((EG18)PointProNets_ChengdeHan.assets/image-20200820215823727.png)

### 3.4 Reprojection

The $H_{N}$ is then denoised by **HDN** to produce $H_{D}$, which is finally converted into a point cloud by Backprojector with the same frame that Projector uses. **Each pixel center** with the corresponding depth given by $H_{D}$ **projects into a 3D point**. **Pixels with zero values are not projected**, as they do not represent geometry , but are rather place holders for no geometry. The resulting consolidated set of points is then translated to the original position of the input patch.

The generated point sets are all retained in a final set representing the consolidated point cloud, without any further processing such as averaging of point locations. In order to introduce overlaps between patches and hence produce a dense output, we evaluate a patch around each input noisy point.

![image-20200820220547751]((EG18)PointProNets_ChengdeHan.assets/image-20200820220547751.png)

![image-20200820220846413]((EG18)PointProNets_ChengdeHan.assets/image-20200820220846413.png)

We back-project points from the heighmap image $H_{G}$ in a square of size m = 24.

### 3.5 Loss

![image-20200820221123743]((EG18)PointProNets_ChengdeHan.assets/image-20200820221123743.png)

首先使用真实的法向量，训练HDN，得到一组可以非常好的可以由噪音的高度图生成非常接近真实高度图的参数。然后固定这组参数，去训练HGN模块。

